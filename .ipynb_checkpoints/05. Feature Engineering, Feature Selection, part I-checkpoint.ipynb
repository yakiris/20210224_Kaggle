{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тема: Feature Engineering, Feature Selection, part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим работу с данными, которые были использованы в ДЗ2 и 3, продолжим решать задачу обнаружения мошеннических транзакций, что позволит получить полное решение задачи / полный пайплайн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/assignment2_data/train.csv')\n",
    "lb = pd.read_csv('../data/assignment2_data/test.csv')\n",
    "\n",
    "X_data = data.drop('isFraud', axis=1)\n",
    "y_data = data['isFraud']\n",
    "\n",
    "X_lb = lb.drop('isFraud', axis=1)\n",
    "y_lb = lb['isFraud']\n",
    "\n",
    "stata = pd.DataFrame(columns=['train_mean', 'train_std', 'valid_mean', 'valid_std', \\\n",
    "                              'valid_conf_interval','auc_lb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 0: выбрать любую модель машинного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_model(X, y, lb_X, lb_y, operation=None):\n",
    "    \n",
    "    # преобразование категориальных признаков\n",
    "    cat_features = X.select_dtypes(exclude=np.number).columns.to_list()\n",
    "    X[cat_features] = X[cat_features].astype('category')\n",
    "    lb_X[cat_features] = lb_X[cat_features].astype('category')\n",
    "    \n",
    "    # обучение модели\n",
    "    X_train, X_valid = train_test_split(X, train_size=0.7, shuffle=True, random_state=5)\n",
    "    y_train, y_valid = train_test_split(y, train_size=0.7, shuffle=True, random_state=5)\n",
    "\n",
    "    model = lgb.LGBMClassifier(objective=\"binary\", n_estimators=1000, random_state=5)\n",
    "\n",
    "    model.fit(X=X_train, y=y_train,\n",
    "                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                categorical_feature=cat_features, # \"auto\",\n",
    "                early_stopping_rounds=25,\n",
    "                eval_metric=\"auc\",\n",
    "                verbose=100)\n",
    "    \n",
    "    # кросс-валидация\n",
    "    fold_train_scores, fold_valid_scores = [], []\n",
    "    \n",
    "    cv_strategy = KFold(n_splits=5, random_state=1)\n",
    "    \n",
    "    for fold_number, (train_idx, valid_idx) in enumerate(cv_strategy.split(X, y)):\n",
    "        X_train, X_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "        fold_train_scores.append(roc_auc_score(y_train, y_train_pred))\n",
    "        fold_valid_scores.append(roc_auc_score(y_valid, y_valid_pred))\n",
    "        \n",
    "    # доверительный интервал\n",
    "    conf_interval = 0.95 \n",
    "        \n",
    "    left_bound = np.percentile(fold_valid_scores, ((1 - conf_interval) / 2) * 100)\n",
    "    right_bound = np.percentile(fold_valid_scores, (conf_interval + ((1 - conf_interval) / 2)) * 100)\n",
    "    \n",
    "    # статистика\n",
    "    if operation != None:\n",
    "        \n",
    "        stata.loc[f'{operation}', 'train_mean'] = round(np.mean(fold_train_scores), 4)\n",
    "        stata.loc[f'{operation}', 'valid_mean'] = round(np.mean(fold_valid_scores), 4)\n",
    "        stata.loc[f'{operation}', 'train_std'] = round(np.std(fold_train_scores), 3)\n",
    "        stata.loc[f'{operation}', 'valid_std'] = round(np.std(fold_valid_scores), 3)\n",
    "        stata.loc[f'{operation}', 'valid_conf_interval'] = f'{round(left_bound, 3)}/{round(right_bound, 3)}'\n",
    "\n",
    "        auc_lb = round(roc_auc_score(lb_y, model.predict_proba(lb_X)[:, 1:]), 4)\n",
    "        stata.loc[f'{operation}', 'auc_lb'] = auc_lb\n",
    "\n",
    "        return stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's auc: 0.975608\ttraining's binary_logloss: 0.0432565\tvalid_1's auc: 0.940201\tvalid_1's binary_logloss: 0.0565885\n",
      "[200]\ttraining's auc: 0.991572\ttraining's binary_logloss: 0.0310524\tvalid_1's auc: 0.94739\tvalid_1's binary_logloss: 0.0519806\n",
      "[300]\ttraining's auc: 0.996377\ttraining's binary_logloss: 0.0233609\tvalid_1's auc: 0.949776\tvalid_1's binary_logloss: 0.0495208\n",
      "[400]\ttraining's auc: 0.998267\ttraining's binary_logloss: 0.0180339\tvalid_1's auc: 0.951945\tvalid_1's binary_logloss: 0.0480682\n",
      "Early stopping, best iteration is:\n",
      "[455]\ttraining's auc: 0.999023\ttraining's binary_logloss: 0.0155787\tvalid_1's auc: 0.952796\tvalid_1's binary_logloss: 0.047524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>valid_conf_interval</th>\n",
       "      <th>auc_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.872/0.907</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_mean train_std valid_mean valid_std valid_conf_interval  auc_lb\n",
       "baseline     0.8892     0.004     0.8877     0.012         0.872/0.907  0.8584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_base = X_data.copy()\n",
    "X_lb_base = X_lb.copy()\n",
    "\n",
    "stata = evaluation_model(X_data_base, y_data, X_lb_base, y_lb, operation='baseline')\n",
    "stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1: признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transform_datetime(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    data[\"DT\"] = pd.to_datetime(data[\"TransactionDT\"], unit='s', origin='2017-11-30')\n",
    "    data[\"year\"] = data[\"DT\"].dt.year\n",
    "    data[\"month\"] = data[\"DT\"].dt.month\n",
    "    data[\"day\"] = data[\"DT\"].dt.day\n",
    "    data[\"hour\"] = data[\"DT\"].dt.hour\n",
    "    data[\"day_of_week\"] = data[\"DT\"].dt.weekday\n",
    "    data = data.drop(\"DT\", axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's auc: 0.976375\ttraining's binary_logloss: 0.042987\tvalid_1's auc: 0.940983\tvalid_1's binary_logloss: 0.0565551\n",
      "[200]\ttraining's auc: 0.99285\ttraining's binary_logloss: 0.0303317\tvalid_1's auc: 0.94775\tvalid_1's binary_logloss: 0.0519683\n",
      "[300]\ttraining's auc: 0.99774\ttraining's binary_logloss: 0.0221381\tvalid_1's auc: 0.950526\tvalid_1's binary_logloss: 0.0493709\n",
      "[400]\ttraining's auc: 0.999239\ttraining's binary_logloss: 0.0168056\tvalid_1's auc: 0.951907\tvalid_1's binary_logloss: 0.0479084\n",
      "[500]\ttraining's auc: 0.999706\ttraining's binary_logloss: 0.0130022\tvalid_1's auc: 0.953485\tvalid_1's binary_logloss: 0.0471269\n",
      "Early stopping, best iteration is:\n",
      "[563]\ttraining's auc: 0.999868\ttraining's binary_logloss: 0.0109897\tvalid_1's auc: 0.954021\tvalid_1's binary_logloss: 0.0468579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>valid_conf_interval</th>\n",
       "      <th>auc_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.872/0.907</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_datetime</th>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.899/0.928</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train_mean train_std valid_mean valid_std  \\\n",
       "baseline               0.8892     0.004     0.8877     0.012   \n",
       "transform_datetime     0.9103     0.004     0.9083     0.011   \n",
       "\n",
       "                   valid_conf_interval  auc_lb  \n",
       "baseline                   0.872/0.907  0.8584  \n",
       "transform_datetime         0.899/0.928  0.8503  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_dt = transform_datetime(X_data)\n",
    "X_lb_dt = transform_datetime(X_lb)\n",
    "\n",
    "stata = evaluation_model(X_data_dt, y_data, X_lb_dt, y_lb, operation='transform_datetime')\n",
    "stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* по сравнению с базовой моделью преобразование признака TransactionDT в datetime увеличило разрыв между показателями кросс-валидации и результом на ЛБ. \n",
    "* гипотеза ухудшила модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: сделать конкатенацию признаков\n",
    "* card1 + card2;\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "\n",
    "Рассматривать их как категориальных признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenation(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    data['card_1_2'] = data['card1'].astype(np.str) + '_' + data['card2'].astype(np.str)\n",
    "    data['card_1_2_3_5'] = data['card_1_2'] + '_' + data['card3'].astype(np.str) + '_' + data['card5'].astype(np.str)\n",
    "    data['card_1_2_3_5_addr_1_2'] = data['card_1_2_3_5'] + '_' + data['addr1'].astype(np.str) + '_' + data['addr2'].astype(np.str)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's auc: 0.993307\ttraining's binary_logloss: 0.0227319\tvalid_1's auc: 0.947786\tvalid_1's binary_logloss: 0.0487738\n",
      "[200]\ttraining's auc: 0.998799\ttraining's binary_logloss: 0.0123169\tvalid_1's auc: 0.952444\tvalid_1's binary_logloss: 0.0464544\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's auc: 0.99915\ttraining's binary_logloss: 0.0109781\tvalid_1's auc: 0.952891\tvalid_1's binary_logloss: 0.0463379\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>valid_conf_interval</th>\n",
       "      <th>auc_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.872/0.907</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_datetime</th>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.899/0.928</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenation</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.933</td>\n",
       "      <td>0.8401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train_mean train_std valid_mean valid_std  \\\n",
       "baseline               0.8892     0.004     0.8877     0.012   \n",
       "transform_datetime     0.9103     0.004     0.9083     0.011   \n",
       "concatenation           0.922     0.003     0.9205      0.01   \n",
       "\n",
       "                   valid_conf_interval  auc_lb  \n",
       "baseline                   0.872/0.907  0.8584  \n",
       "transform_datetime         0.899/0.928  0.8503  \n",
       "concatenation              0.908/0.933  0.8401  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_concat = concatenation(X_data)\n",
    "X_lb_concat = concatenation(X_lb)\n",
    "\n",
    "stata = evaluation_model(X_data_concat, y_data, X_lb_concat, y_lb, operation='concatenation')\n",
    "stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* по сравнению с базовой моделью конкатинация признаков увеличила разрыв между показателями кросс-валидации и результом на ЛБ. \n",
    "* гипотеза ухудшила модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3: Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrequencyEncoder(data, features):\n",
    "    \n",
    "    data = data.copy()\n",
    "\n",
    "    for feature in features:\n",
    "        freq_encoder = data[feature].value_counts(normalize=True)\n",
    "        data[f\"{feature}_freq_enc\"] = data[feature].map(freq_encoder)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's auc: 0.977712\ttraining's binary_logloss: 0.0423063\tvalid_1's auc: 0.941587\tvalid_1's binary_logloss: 0.0561101\n",
      "[200]\ttraining's auc: 0.993025\ttraining's binary_logloss: 0.0296955\tvalid_1's auc: 0.951308\tvalid_1's binary_logloss: 0.0507267\n",
      "[300]\ttraining's auc: 0.997424\ttraining's binary_logloss: 0.0220766\tvalid_1's auc: 0.954336\tvalid_1's binary_logloss: 0.0482006\n",
      "Early stopping, best iteration is:\n",
      "[337]\ttraining's auc: 0.998232\ttraining's binary_logloss: 0.0199437\tvalid_1's auc: 0.955214\tvalid_1's binary_logloss: 0.0474744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>valid_conf_interval</th>\n",
       "      <th>auc_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.872/0.907</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_datetime</th>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.899/0.928</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenation</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.933</td>\n",
       "      <td>0.8401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency_encoder</th>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.855/0.892</td>\n",
       "      <td>0.8522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train_mean train_std valid_mean valid_std  \\\n",
       "baseline               0.8892     0.004     0.8877     0.012   \n",
       "transform_datetime     0.9103     0.004     0.9083     0.011   \n",
       "concatenation           0.922     0.003     0.9205      0.01   \n",
       "frequency_encoder      0.8696     0.005     0.8678     0.014   \n",
       "\n",
       "                   valid_conf_interval  auc_lb  \n",
       "baseline                   0.872/0.907  0.8584  \n",
       "transform_datetime         0.899/0.928  0.8503  \n",
       "concatenation              0.908/0.933  0.8401  \n",
       "frequency_encoder          0.855/0.892  0.8522  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2']\n",
    "\n",
    "X_data_freq = FrequencyEncoder(X_data, features)\n",
    "X_lb_freq = FrequencyEncoder(X_lb, features)\n",
    "\n",
    "stata = evaluation_model(X_data_freq, y_data, X_lb_freq, y_lb, operation='frequency_encoder')\n",
    "stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* по сравнению с базовой моделью FrequencyEncoder признаков увеличило среднеквадратичное отклонение и доверительный интервал модели на валидационной выборке. \n",
    "* гипотеза ухудшила модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4: Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggs(data, groupby_id, aggs=None, features=None):\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    if aggs != None:\n",
    "        data_grouped_num = data.groupby(groupby_id)\n",
    "        stats_num = data_grouped_num.agg(aggs)\n",
    "        stats_num.columns = [f\"{feature}_{stat}\" for feature, stat in stats_num]\n",
    "        stats_num = stats_num.reset_index()\n",
    "        data = data.merge(stats_num, how='left', on=groupby_id)\n",
    "    \n",
    "    if features != None:\n",
    "        categorical = data[features].copy()\n",
    "        le = LabelEncoder()\n",
    "        for feature in features:\n",
    "            cat_value = list(categorical[feature].values.astype('str'))\n",
    "            le.fit(cat_value)\n",
    "            categorical[feature] = le.transform(cat_value)\n",
    "        categorical[groupby_id] = data[groupby_id]\n",
    "        data_grouped_cat = categorical.groupby(groupby_id)\n",
    "        stats_cat = data_grouped_cat.agg({col: [\"mean\", \"sum\"] for col in features})\n",
    "        stats_cat.columns = [f\"{feature}_{stat}\" for feature, stat in stats_cat]\n",
    "        stats_cat = stats_cat.reset_index()\n",
    "        data = data.merge(stats_cat, how='left', on=groupby_id)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's auc: 0.993559\ttraining's binary_logloss: 0.0215903\tvalid_1's auc: 0.948447\tvalid_1's binary_logloss: 0.0480976\n",
      "[200]\ttraining's auc: 0.999148\ttraining's binary_logloss: 0.0105727\tvalid_1's auc: 0.954545\tvalid_1's binary_logloss: 0.0455159\n",
      "Early stopping, best iteration is:\n",
      "[216]\ttraining's auc: 0.999388\ttraining's binary_logloss: 0.00942071\tvalid_1's auc: 0.955455\tvalid_1's binary_logloss: 0.0453587\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>valid_conf_interval</th>\n",
       "      <th>auc_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.872/0.907</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_datetime</th>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.899/0.928</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenation</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.933</td>\n",
       "      <td>0.8401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency_encoder</th>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.855/0.892</td>\n",
       "      <td>0.8522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregating_TransactionAmt</th>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.92/0.937</td>\n",
       "      <td>0.8344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train_mean train_std valid_mean valid_std  \\\n",
       "baseline                       0.8892     0.004     0.8877     0.012   \n",
       "transform_datetime             0.9103     0.004     0.9083     0.011   \n",
       "concatenation                   0.922     0.003     0.9205      0.01   \n",
       "frequency_encoder              0.8696     0.005     0.8678     0.014   \n",
       "aggregating_TransactionAmt     0.9282     0.002     0.9276     0.007   \n",
       "\n",
       "                           valid_conf_interval  auc_lb  \n",
       "baseline                           0.872/0.907  0.8584  \n",
       "transform_datetime                 0.899/0.928  0.8503  \n",
       "concatenation                      0.908/0.933  0.8401  \n",
       "frequency_encoder                  0.855/0.892  0.8522  \n",
       "aggregating_TransactionAmt          0.92/0.937  0.8344  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = {\"card1\": [np.mean, np.std],\n",
    "        \"card2\": [np.mean, np.std],\n",
    "        \"card3\": [np.mean, np.std],\n",
    "        \"card5\": [np.mean, np.std],\n",
    "        \"addr1\": [np.mean, np.std],\n",
    "        \"addr2\": [np.mean, np.std]\n",
    "        }\n",
    "\n",
    "features = [\"card4\", \"card6\", \"card_1_2\", \"card_1_2_3_5\", \"card_1_2_3_5_addr_1_2\"]\n",
    "\n",
    "groupby_id = \"TransactionAmt\"\n",
    "    \n",
    "X_data_agg_amt = create_aggs(X_data_concat, groupby_id, aggs, features)\n",
    "X_lb_agg_amt = create_aggs(X_lb_concat, groupby_id, aggs, features)\n",
    "\n",
    "stata = evaluation_model(X_data_agg_amt, y_data, X_lb_agg_amt, y_lb, operation='aggregating_TransactionAmt')\n",
    "stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* по сравнению с базовой моделью создание новых признаков TransactionAmt к вычисленной статистике увеличило разрыв между показателями кросс-валидации и результом на ЛБ.\n",
    "* гипотеза ухудшила модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5: Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's auc: 0.993511\ttraining's binary_logloss: 0.0222547\tvalid_1's auc: 0.949163\tvalid_1's binary_logloss: 0.0483855\n",
      "[200]\ttraining's auc: 0.998708\ttraining's binary_logloss: 0.0120595\tvalid_1's auc: 0.954198\tvalid_1's binary_logloss: 0.0456436\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's auc: 0.998811\ttraining's binary_logloss: 0.0114171\tvalid_1's auc: 0.954524\tvalid_1's binary_logloss: 0.0454885\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>valid_conf_interval</th>\n",
       "      <th>auc_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.872/0.907</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_datetime</th>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.899/0.928</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenation</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.933</td>\n",
       "      <td>0.8401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency_encoder</th>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.855/0.892</td>\n",
       "      <td>0.8522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregating_TransactionAmt</th>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.92/0.937</td>\n",
       "      <td>0.8344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregating_D15</th>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.932</td>\n",
       "      <td>0.8403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train_mean train_std valid_mean valid_std  \\\n",
       "baseline                       0.8892     0.004     0.8877     0.012   \n",
       "transform_datetime             0.9103     0.004     0.9083     0.011   \n",
       "concatenation                   0.922     0.003     0.9205      0.01   \n",
       "frequency_encoder              0.8696     0.005     0.8678     0.014   \n",
       "aggregating_TransactionAmt     0.9282     0.002     0.9276     0.007   \n",
       "aggregating_D15                0.9205     0.003     0.9191      0.01   \n",
       "\n",
       "                           valid_conf_interval  auc_lb  \n",
       "baseline                           0.872/0.907  0.8584  \n",
       "transform_datetime                 0.899/0.928  0.8503  \n",
       "concatenation                      0.908/0.933  0.8401  \n",
       "frequency_encoder                  0.855/0.892  0.8522  \n",
       "aggregating_TransactionAmt          0.92/0.937  0.8344  \n",
       "aggregating_D15                    0.908/0.932  0.8403  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_id = \"D15\"\n",
    "\n",
    "X_data_agg_d15 = create_aggs(X_data_concat, groupby_id, aggs, features)\n",
    "X_lb_agg_d15 = create_aggs(X_lb_concat, groupby_id, aggs, features)\n",
    "\n",
    "stata = evaluation_model(X_data_agg_d15, y_data, X_lb_agg_d15, y_lb, operation='aggregating_D15')\n",
    "stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* по сравнению с базовой моделью создание новых признаков D15 к вычисленной статистике увеличило разрыв между показателями кросс-валидации и результом на ЛБ.\n",
    "* гипотеза ухудшила модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6: выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_TransactionAmt(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    data['TransactionAmt_whole'] = data['TransactionAmt']//1\n",
    "    data['TransactionAmt_frac'] = data['TransactionAmt']%1\n",
    "    data['TransactionAmt_log'] = np.log2(data['TransactionAmt'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's auc: 0.977391\ttraining's binary_logloss: 0.0429455\tvalid_1's auc: 0.939139\tvalid_1's binary_logloss: 0.0567328\n",
      "[200]\ttraining's auc: 0.991944\ttraining's binary_logloss: 0.0305835\tvalid_1's auc: 0.946859\tvalid_1's binary_logloss: 0.0519318\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttraining's auc: 0.995263\ttraining's binary_logloss: 0.0254212\tvalid_1's auc: 0.948995\tvalid_1's binary_logloss: 0.0501956\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>valid_conf_interval</th>\n",
       "      <th>auc_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.872/0.907</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_datetime</th>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.899/0.928</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenation</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.933</td>\n",
       "      <td>0.8401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency_encoder</th>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.855/0.892</td>\n",
       "      <td>0.8522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregating_TransactionAmt</th>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.92/0.937</td>\n",
       "      <td>0.8344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregating_D15</th>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.932</td>\n",
       "      <td>0.8403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_TransactionAmt</th>\n",
       "      <td>0.8453</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.82/0.866</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train_mean train_std valid_mean valid_std  \\\n",
       "baseline                       0.8892     0.004     0.8877     0.012   \n",
       "transform_datetime             0.9103     0.004     0.9083     0.011   \n",
       "concatenation                   0.922     0.003     0.9205      0.01   \n",
       "frequency_encoder              0.8696     0.005     0.8678     0.014   \n",
       "aggregating_TransactionAmt     0.9282     0.002     0.9276     0.007   \n",
       "aggregating_D15                0.9205     0.003     0.9191      0.01   \n",
       "transform_TransactionAmt       0.8453     0.005     0.8437     0.017   \n",
       "\n",
       "                           valid_conf_interval  auc_lb  \n",
       "baseline                           0.872/0.907  0.8584  \n",
       "transform_datetime                 0.899/0.928  0.8503  \n",
       "concatenation                      0.908/0.933  0.8401  \n",
       "frequency_encoder                  0.855/0.892  0.8522  \n",
       "aggregating_TransactionAmt          0.92/0.937  0.8344  \n",
       "aggregating_D15                    0.908/0.932  0.8403  \n",
       "transform_TransactionAmt            0.82/0.866  0.8585  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_trans_amt = transform_TransactionAmt(X_data)\n",
    "X_lb_trans_amt = transform_TransactionAmt(X_lb)\n",
    "\n",
    "stata = evaluation_model(X_data_trans_amt, y_data, X_lb_trans_amt, y_lb, operation='transform_TransactionAmt')\n",
    "stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* по сравнению с базовой моделью трансформация признака TransactionAmt сократила разрыв между показателями кросс-валидации и результом на ЛБ.\n",
    "* гипотеза улудшила модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7 (опция): выполнить предварительную подготовку / очистку признаков P_emaildomain и R_emaildomain (что и как делать - остается на ваше усмотрение) и сделать Frequency Encoding для очищенных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_emaildomain(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    # отсутствующие значения P_emaildomain заполнить данными из R_emaildomain\n",
    "    condition = (data['P_emaildomain'].isnull()) & (data['R_emaildomain'].notnull())\n",
    "    data.loc[condition, 'P_emaildomain'] = data.loc[condition, 'R_emaildomain']\n",
    "\n",
    "    # разбиение домена на уровни\n",
    "    new = data['P_emaildomain'].str.split(\".\", n = 1, expand = True)\n",
    "    data['P_emaildomain_1'] = new[0]\n",
    "    data['P_emaildomain_2'] = new[1]\n",
    "\n",
    "    # R_emaildomain, P_emaildomain удалить\n",
    "    data = data.drop(['R_emaildomain', 'P_emaildomain'], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's auc: 0.974763\ttraining's binary_logloss: 0.0435906\tvalid_1's auc: 0.94018\tvalid_1's binary_logloss: 0.0563676\n",
      "[200]\ttraining's auc: 0.990899\ttraining's binary_logloss: 0.0311994\tvalid_1's auc: 0.949099\tvalid_1's binary_logloss: 0.0514398\n",
      "[300]\ttraining's auc: 0.996319\ttraining's binary_logloss: 0.0235105\tvalid_1's auc: 0.951078\tvalid_1's binary_logloss: 0.0493871\n",
      "[400]\ttraining's auc: 0.998597\ttraining's binary_logloss: 0.0178591\tvalid_1's auc: 0.952329\tvalid_1's binary_logloss: 0.0480119\n",
      "Early stopping, best iteration is:\n",
      "[427]\ttraining's auc: 0.99887\ttraining's binary_logloss: 0.0166664\tvalid_1's auc: 0.952809\tvalid_1's binary_logloss: 0.0477265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>valid_conf_interval</th>\n",
       "      <th>auc_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.872/0.907</td>\n",
       "      <td>0.8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_datetime</th>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.899/0.928</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenation</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.933</td>\n",
       "      <td>0.8401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency_encoder</th>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.855/0.892</td>\n",
       "      <td>0.8522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregating_TransactionAmt</th>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.92/0.937</td>\n",
       "      <td>0.8344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregating_D15</th>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.908/0.932</td>\n",
       "      <td>0.8403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_TransactionAmt</th>\n",
       "      <td>0.8453</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.82/0.866</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform_emaildomain</th>\n",
       "      <td>0.8854</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8836</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.867/0.905</td>\n",
       "      <td>0.8472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train_mean train_std valid_mean valid_std  \\\n",
       "baseline                       0.8892     0.004     0.8877     0.012   \n",
       "transform_datetime             0.9103     0.004     0.9083     0.011   \n",
       "concatenation                   0.922     0.003     0.9205      0.01   \n",
       "frequency_encoder              0.8696     0.005     0.8678     0.014   \n",
       "aggregating_TransactionAmt     0.9282     0.002     0.9276     0.007   \n",
       "aggregating_D15                0.9205     0.003     0.9191      0.01   \n",
       "transform_TransactionAmt       0.8453     0.005     0.8437     0.017   \n",
       "transform_emaildomain          0.8854     0.004     0.8836     0.014   \n",
       "\n",
       "                           valid_conf_interval  auc_lb  \n",
       "baseline                           0.872/0.907  0.8584  \n",
       "transform_datetime                 0.899/0.928  0.8503  \n",
       "concatenation                      0.908/0.933  0.8401  \n",
       "frequency_encoder                  0.855/0.892  0.8522  \n",
       "aggregating_TransactionAmt          0.92/0.937  0.8344  \n",
       "aggregating_D15                    0.908/0.932  0.8403  \n",
       "transform_TransactionAmt            0.82/0.866  0.8585  \n",
       "transform_emaildomain              0.867/0.905  0.8472  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_trans_email = transform_emaildomain(X_data)\n",
    "X_lb_trans_email = transform_emaildomain(X_lb)\n",
    "\n",
    "stata = evaluation_model(X_data_trans_email, y_data, X_lb_trans_email, y_lb, operation='transform_emaildomain')\n",
    "stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* по сравнению с базовой моделью трансформация признаков emaildomain увеличила среднеквадратичное отклонение и доверительный интервал модели на валидационной выборке. \n",
    "* гипотеза ухудшила модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
